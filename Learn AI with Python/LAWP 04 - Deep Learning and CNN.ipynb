{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48ef33d-e339-4da1-a41b-ec8435e97eee",
   "metadata": {},
   "source": [
    "# Chapter 10 - Implementing Deep Learning (DL) and Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60b2977-b93b-43cb-aaff-04548e46be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ff1fb-5867-47e2-8f70-b74b9196dbfc",
   "metadata": {},
   "source": [
    "### Create the Dataset\n",
    "\n",
    "Source: https://www.microsoft.com/en-us/download/details.aspx?id=54765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ecae07-0768-43fe-93e8-083fa598db94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test directories are ready with images organized by category.\n"
     ]
    }
   ],
   "source": [
    "# Set paths for the dataset\n",
    "cat_path = './dogs-vs-cats/cats'\n",
    "dog_path = './dogs-vs-cats/dogs'\n",
    "\n",
    "# Prepare lists for cat and dog image file paths\n",
    "cat_images = [os.path.join(cat_path, img) for img in os.listdir(cat_path) if img.endswith('.jpg')]\n",
    "dog_images = [os.path.join(dog_path, img) for img in os.listdir(dog_path) if img.endswith('.jpg')]\n",
    "\n",
    "# Combine all images and create labels (0 for cat, 1 for dog)\n",
    "all_images = cat_images + dog_images\n",
    "all_labels = [0] * len(cat_images) + [1] * len(dog_images)\n",
    "\n",
    "# Shuffle the dataset and labels together\n",
    "combined = list(zip(all_images, all_labels))\n",
    "random.shuffle(combined)\n",
    "all_images, all_labels = zip(*combined)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create directories to store the training and testing data\n",
    "base_train_path = './dogs-vs-cats/train'\n",
    "base_test_path = './dogs-vs-cats/test'\n",
    "\n",
    "for folder in [base_train_path, base_test_path]:\n",
    "    for label in ['cat', 'dog']:\n",
    "        os.makedirs(os.path.join(folder, label), exist_ok=True)\n",
    "\n",
    "# Move images to the train and test directories based on labels\n",
    "for img, label in zip(train_images, train_labels):\n",
    "    label_folder = 'cat' if label == 0 else 'dog'\n",
    "    shutil.copy(img, os.path.join(base_train_path, label_folder))\n",
    "\n",
    "for img, label in zip(test_images, test_labels):\n",
    "    label_folder = 'cat' if label == 0 else 'dog'\n",
    "    shutil.copy(img, os.path.join(base_test_path, label_folder))\n",
    "\n",
    "print(\"Train and Test directories are ready with images organized by category.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a36bde2-9db5-4cdc-b240-a5fe120e0389",
   "metadata": {},
   "source": [
    "### Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac785f92-3ace-42f6-9276-c494ee63d6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing problematic image: ./dogs-vs-cats/train/cat\\10744.jpg_temp.jpg\n",
      "Image cleaning process completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# Define the directories to check\n",
    "directories = ['./dogs-vs-cats/train/cat', './dogs-vs-cats/train/dog', './dogs-vs-cats/test/cat', './dogs-vs-cats/test/dog']\n",
    "\n",
    "# Iterate through each directory to check and clean images\n",
    "for i in range(3):  # Run multiple passes to ensure all corrupted images are removed\n",
    "    for directory in directories:\n",
    "        for filename in os.listdir(directory):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                # Ignore warnings during image processing\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    with Image.open(filepath) as img:  # Try opening the image file\n",
    "                        img.verify()                   # Verify if it's an image\n",
    "                        img = Image.open(filepath)     # Open it again to try loading the image properly\n",
    "                        img.load()                     # Ensure that the entire image is loaded properly\n",
    "            except (IOError, SyntaxError, UnidentifiedImageError) as e:\n",
    "                # Remove the problematic file if an error occurs during verification or loading\n",
    "                print(f\"Removing problematic image: {filepath}\")\n",
    "                os.remove(filepath)\n",
    "\n",
    "print(\"Image cleaning process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1def6f-1910-4140-913d-0c00b09be30a",
   "metadata": {},
   "source": [
    "### Preparing the Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca68a69a-c6fa-4cac-a3c9-4e6ca6473f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25003 images belonging to 2 classes.\n",
      "Found 23631 images belonging to 2 classes.\n",
      "Training and Test sets are ready for model training.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define constants for image size\n",
    "Image_Width = 128                          # Set the width of the images to 128 pixels\n",
    "Image_Height = 128                         # Set the height of the images to 128 pixels\n",
    "Image_Size = (Image_Width, Image_Height)   # Define the image size as a tuple (128, 128)\n",
    "batch_size = 32                            # Set the batch size to 32 images per batch\n",
    "\n",
    "# Initialize ImageDataGenerator for training and testing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)  # Rescale images to normalize pixel values between 0 and 1\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)   # Rescale testing images to normalize pixel values between 0 and 1\n",
    "\n",
    "# Create training and testing sets using flow_from_directory\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    './dogs-vs-cats/train',                # Path to the training dataset directory\n",
    "    target_size=Image_Size,                # Resize all images to (128, 128)\n",
    "    batch_size=batch_size,                 # Load images in batches of 32\n",
    "    class_mode='binary'                    # Define class mode as 'binary' since there are only two classes (cat and dog)\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    './dogs-vs-cats/test',                 # Path to the testing dataset directory\n",
    "    target_size=Image_Size,                # Resize all images to (128, 128)\n",
    "    batch_size=batch_size,                 # Load images in batches of 32\n",
    "    class_mode='binary'                    # Define class mode as 'binary' since there are only two classes (cat and dog)\n",
    ")\n",
    "\n",
    "print(\"Training and Test sets are ready for model training.\")  # Print a message indicating that the training and testing sets are ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d55689-6520-4b93-addd-df00ee365302",
   "metadata": {},
   "source": [
    "### Create the Neural Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67276462-03e7-411d-ab8b-a0942cc00802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 170s 270ms/step - loss: 0.6087 - accuracy: 0.6639 - val_loss: 0.5087 - val_accuracy: 0.7464\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 171s 273ms/step - loss: 0.4770 - accuracy: 0.7686 - val_loss: 0.4614 - val_accuracy: 0.7703\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 169s 271ms/step - loss: 0.4097 - accuracy: 0.8144 - val_loss: 0.3461 - val_accuracy: 0.8529\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 174s 279ms/step - loss: 0.3330 - accuracy: 0.8539 - val_loss: 0.2654 - val_accuracy: 0.8925\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 177s 283ms/step - loss: 0.2542 - accuracy: 0.8963 - val_loss: 0.1628 - val_accuracy: 0.9445\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 170s 273ms/step - loss: 0.1801 - accuracy: 0.9305 - val_loss: 0.1469 - val_accuracy: 0.9494\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 170s 272ms/step - loss: 0.1236 - accuracy: 0.9534 - val_loss: 0.0826 - val_accuracy: 0.9767\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 172s 274ms/step - loss: 0.0771 - accuracy: 0.9737 - val_loss: 0.0447 - val_accuracy: 0.9867\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 171s 274ms/step - loss: 0.0502 - accuracy: 0.9831 - val_loss: 0.0302 - val_accuracy: 0.9942\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 0.0413 - accuracy: 0.9860 - val_loss: 0.0238 - val_accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2eeadbb8e10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential                            # Import Sequential to initialize a sequential neural network model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense  # Import layers for building the CNN model\n",
    "\n",
    "# Initializing the CNN model\n",
    "model = Sequential()                        # Create a sequential model which allows adding layers one by one\n",
    "\n",
    "# Adding Convolution Layer\n",
    "model.add(Conv2D(32,                        # Add a 2D convolutional layer with 32 filters\n",
    "                 (3, 3),                    # Each filter is 3x3 in size\n",
    "                 input_shape=(128, 128, 3), # Input shape is set to (128, 128, 3) for 128x128 RGB images\n",
    "                 activation='relu'))        # Use ReLU activation to introduce non-linearity\n",
    "\n",
    "# Adding Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   # Add a max pooling layer with pool size 2x2 to reduce dimensionality\n",
    "\n",
    "# Adding another Convolution Layer\n",
    "model.add(Conv2D(32,                        # Add another 2D convolutional layer with 32 filters\n",
    "                 (3, 3),                    # Each filter is 3x3 in size\n",
    "                 activation='relu'))        # Use ReLU activation to introduce non-linearity again\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   # Add another max pooling layer with pool size 2x2\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())                        # Flatten the pooled feature maps to create a single feature vector\n",
    "\n",
    "# Full Connection (Fully Connected Layer)\n",
    "model.add(Dense(units=128,                  # Add a fully connected layer with 128 neurons\n",
    "                activation='relu'))         # Use ReLU activation\n",
    "\n",
    "model.add(Dense(units=1,                    # Add an output layer with 1 neuron (for binary classification)\n",
    "                activation='sigmoid'))      # Use sigmoid activation to get a probability output between 0 and 1\n",
    "\n",
    "# Compiling the CNN\n",
    "model.compile(optimizer='adam',             # Compile the model using the Adam optimizer\n",
    "              loss='binary_crossentropy',   # Use binary crossentropy as the loss function (since it’s a binary classification problem)\n",
    "              metrics=['accuracy'])         # Track the accuracy of the model during training\n",
    "\n",
    "# Fitting the CNN to the Training Set\n",
    "model.fit(training_set,                     # Train the model using the training data\n",
    "          steps_per_epoch=625,              # Number of batches per epoch (20000 images / batch_size 32 = 625)\n",
    "          epochs=10,                        # Train the model for 10 epochs\n",
    "          validation_data=test_set,         # Use the test set for validation during training\n",
    "          validation_steps=157)             # Number of validation batches per epoch (5000 images / batch_size 32 ≈ 157)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e154c-2841-4d4e-b022-0a7e18cb7bd4",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "904cd9a0-02c9-4550-a710-2c70f1a17c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28800)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3686528   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3696801 (14.10 MB)\n",
      "Trainable params: 3696801 (14.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d4796-3312-4663-994b-21fe4837d79c",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "**Accuracy:** Your model's accuracy started at around 66% and ended up at around 99.36% after 10 epochs, which is excellent. The model is now able to predict correctly for almost all the training images.\n",
    "\n",
    "**Validation Accuracy:** The validation accuracy has also significantly improved, reaching around 99.24%, indicating that the model generalizes well to the unseen test data.\n",
    "\n",
    "**Loss:** Both training and validation loss decreased consistently, indicating that the model is effectively learning from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425111a-28f5-42e3-b622-decf4f25fe3c",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d21891-fa6c-450d-aed6-a3c2ed04b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "#model.save('cats_vs_dogs_model.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bebf8d-c07a-4fdb-b665-2a23bfa05ab2",
   "metadata": {},
   "source": [
    "### Make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fa70e28-f4ae-4bec-81ed-65f3245007f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import load_img, img_to_array\n",
    "\n",
    "def predict_image(model, image_path):\n",
    "    \n",
    "    # Load an image to make a prediction\n",
    "    img = load_img(image_path, target_size=(128, 128))  # Load and resize the image\n",
    "    img = img_to_array(img)                             # Convert the image to a NumPy array\n",
    "    img = img / 255.0                                   # Normalize pixel values to be between 0 and 1\n",
    "    img = img.reshape(1, 128, 128, 3)                   # Reshape to add batch dimension\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(img)\n",
    "    if prediction[0][0] > 0.5:\n",
    "        return \"It's a Dog!\"\n",
    "    else:\n",
    "        return \"It's a Cat!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbb30d-756b-41e7-b0a4-d9dce10f1f5b",
   "metadata": {},
   "source": [
    "```Python\n",
    "### Loading Model for prediction\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('cats_vs_dogs_model.h5')\n",
    "\n",
    "# Predict an image using the loaded model\n",
    "result = predict_image(model, 'path/to/your/image.jpg')\n",
    "print(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99841fda-af2c-4d16-9be0-cf04d427a7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 167ms/step\n",
      "It's a Dog!\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "result = predict_image(model, './dogs-vs-cats/dogs/39.jpg')\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
